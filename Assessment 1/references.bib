
@misc{noauthor_pyspark_nodate,
	title = {{PySpark} {Overview} — {PySpark} 3.5.4 documentation},
	url = {https://spark.apache.org/docs/latest/api/python/index.html},
	urldate = {2024-12-22},
	file = {MLlib (DataFrame-based) — PySpark 3.5.4 documentation:/Users/vishal/Zotero/storage/RQ92MT4P/index.html:text/html},
}

@misc{liao_prototyping_2018,
	title = {Prototyping a {Recommender} {System} {Step} by {Step} {Part} 1: {KNN} {Item}-{Based} {Collaborative} {Filtering}},
	shorttitle = {Prototyping a {Recommender} {System} {Step} by {Step} {Part} 1},
	url = {https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea},
	abstract = {Recommender Systems},
	language = {en},
	urldate = {2024-12-22},
	journal = {Medium},
	author = {Liao, Kevin},
	month = nov,
	year = {2018},
	file = {Snapshot:/Users/vishal/Zotero/storage/SAZRZQB6/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637.html:text/html},
}

@misc{liao_prototyping_2018-1,
	title = {Prototyping a {Recommender} {System} {Step} by {Step} {Part} 2: {Alternating} {Least} {Square} ({ALS}) {Matrix}…},
	shorttitle = {Prototyping a {Recommender} {System} {Step} by {Step} {Part} 2},
	url = {https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1},
	abstract = {In the last post, we covered a lot of ground in how to build our own recommender systems. We also got our hand dirty with Pandas and…},
	language = {en},
	urldate = {2024-12-22},
	journal = {Medium},
	author = {Liao, Kevin},
	month = nov,
	year = {2018},
	file = {Snapshot:/Users/vishal/Zotero/storage/9MU5IX3X/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c5.html:text/html},
}

@misc{induraj_which_2023,
	title = {Which {Metrics} in {Regression} matter the most? {MSE}{\textbar}{RMSE}{\textbar}{MAE}{\textbar}{R2}{\textbar}{Adj} {R2}- {Advantages}/{Disadvantages}},
	shorttitle = {Which {Metrics} in {Regression} matter the most?},
	url = {https://induraj2020.medium.com/which-metrics-in-regression-matter-the-most-mse-rmse-mae-r2-adj-r2-advantages-disadvantages-55740cb873ec},
	abstract = {Different metrics can be used to evaluate the performance of regression models, and the choice of metric depends on the specific problem…},
	language = {en},
	urldate = {2024-12-22},
	journal = {Medium},
	author = {Induraj},
	month = feb,
	year = {2023},
	file = {Snapshot:/Users/vishal/Zotero/storage/X3YN59X6/which-metrics-in-regression-matter-the-most-mse-rmse-mae-r2-adj-r2-advantages-disadvantages-557.html:text/html},
}

@article{maitrey_mapreduce_2015,
	series = {3rd {International} {Conference} on {Recent} {Trends} in {Computing} 2015 ({ICRTC}-2015)},
	title = {{MapReduce}: {Simplified} {Data} {Analysis} of {Big} {Data}},
	volume = {57},
	issn = {1877-0509},
	shorttitle = {{MapReduce}},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915019213},
	doi = {10.1016/j.procs.2015.07.392},
	abstract = {With the development of computer technology, there is a tremendous increase in the growth of data. Scientists are overwhelmed with this increasing amount of data processing needs which is getting arisen from every science field. A big problem has been encountered in various fields for making the full use of these large scale data which support decision making. Data mining is the technique that can discovers new patterns from large data sets. For many years it has been studied in all kinds of application area and thus many data mining methods have been developed and applied to practice. But there was a tremendous increase in the amount of data, their computation and analyses in recent years. In such situation most classical data mining methods became out of reach in practice to handle such big data. Efficient parallel/concurrent algorithms and implementation techniques are the key to meeting the scalability and performance requirements entailed in such large scale data mining analyses. Number of parallel algorithms has been implemented by making the use of different parallelization techniques which can be listed as: threads, MPI, MapReduce, and mash-up or workflow technologies that yields different performance and usability characteristics. MPI model is found to be efficient in computing the rigorous problems, especially in simulation. But it is not easy to be used in real. MapReduce is developed from the data analysis model of the information retrieval field and is a cloud technology. Till now, several MapReduce architectures has been developed for handling the big data. The most famous is the Google. The other one having such features is Hadoop which is the most popular open source MapReduce software adopted by many huge IT companies, such as Yahoo, Facebook, eBay and so on. In this paper, we focus specifically on Hadoop and its implementation of MapReduce for analytical processing.},
	urldate = {2024-12-28},
	journal = {Procedia Computer Science},
	author = {Maitrey, Seema and Jha, C. K.},
	month = jan,
	year = {2015},
	keywords = {Big Data, Data Mining, Hadoop., HDFS, MapReduce, parallelization Techniques},
	pages = {563--571},
	file = {ScienceDirect Snapshot:/Users/vishal/Zotero/storage/GBEKDNN6/S1877050915019213.html:text/html},
}

@article{junaid_performance_2022,
	title = {Performance {Evaluation} of {Data}-driven {Intelligent} {Algorithms} for {Big} data {Ecosystem}},
	volume = {126},
	issn = {0929-6212, 1572-834X},
	url = {https://link.springer.com/10.1007/s11277-021-09362-7},
	doi = {10.1007/s11277-021-09362-7},
	abstract = {Artificial intelligence, specifically machine learning, has been applied in a variety of methods by the research group to transform several data sources into valuable facts and understanding, allowing for superior pattern identification skills. Machine learning algorithms on huge and complicated data sets, computationally expensive on the other hand, processing requires hardware and logical resources, such as space, CPU, and memory. As the amount of data created daily reaches quintillion bytes, A complex big data infrastructure becomes more and more relevant. Apache Spark Machine learning library (ML-lib) is a famous platform used for big data analysis, it includes several useful features for machine learning applications, involving regression, classification, and dimension reduction, as well as clustering and features extraction. In this contribution, we consider Apache Spark ML-lib as a computationally independent machine learning library, which is open-source, distributed, scalable, and platform. We have evaluated and compared several ML algorithms to analyze the platform’s qualities, compared Apache Spark ML-lib against Rapid Miner and Sklearn, which are two additional Big data and machine learning processing platforms. Logistic Classifier (LC), Decision Tree Classifier (DTc), Random Forest Classifier (RFC), and Gradient Boosted Tree Classifier (GBTC) are four machine learning algorithms that are compared across platforms. In addition, we have tested general regression methods such as Linear Regressor (LR), Decision Tree Regressor (DTR), Random Forest Regressor (RFR), and Gradient Boosted Tree Regressor (GBTR) on SUSY and Higgs datasets. Moreover, We have evaluated the unsupervised learning methods like K-means and Gaussian Mixer Models on the data set SUSY and Hepmass to determine the robustness of PySpark, in comparison with the classification and regression models. We used ”SUSY,” ”HIGGS,” ”BANK,” and ”HEPMASS” dataset from the UCI data repository. We also talk about recent developments in the research into Big Data machines and provide future research directions.},
	language = {en},
	number = {3},
	urldate = {2024-12-29},
	journal = {Wireless Personal Communications},
	author = {Junaid, Muhammad and Ali, Sajid and Siddiqui, Isma Farah and Nam, Choonsung and Qureshi, Nawab Muhammad Faseeh and Kim, Jaehyoun and Shin, Dong Ryeol},
	month = oct,
	year = {2022},
	pages = {2403--2423},
	file = {PDF:/Users/vishal/Zotero/storage/IUXMFL2J/Junaid et al. - 2022 - Performance Evaluation of Data-driven Intelligent Algorithms for Big data Ecosystem.pdf:application/pdf},
}

@misc{mishra_movie_2024,
	title = {Movie {Recommendation} {System} {Using} {Alternating} {Least} {Squares}},
	url = {https://medium.com/@anurag.tech/movie-recommendation-system-using-alternating-least-squares-14c7bed98f08},
	abstract = {In this blog, We will go through the step-by-step process of building a recommendation system using the ALS algorithm. In the end, I will…},
	language = {en},
	urldate = {2024-12-29},
	journal = {Medium},
	author = {Mishra, Anurag},
	month = aug,
	year = {2024},
	file = {Snapshot:/Users/vishal/Zotero/storage/27KC3CKH/movie-recommendation-system-using-alternating-least-squares-14c7bed98f08.html:text/html},
}

@article{koren_matrix_2009,
	title = {Matrix {Factorization} {Techniques} for {Recommender} {Systems}},
	volume = {42},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9162},
	url = {http://ieeexplore.ieee.org/document/5197422/},
	doi = {10.1109/MC.2009.263},
	language = {en},
	number = {8},
	urldate = {2024-12-29},
	journal = {Computer},
	author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
	month = aug,
	year = {2009},
	pages = {30--37},
	file = {PDF:/Users/vishal/Zotero/storage/MSNE83KL/Koren et al. - 2009 - Matrix Factorization Techniques for Recommender Systems.pdf:application/pdf},
}

@article{hashem_mapreduce_2016,
	title = {{MapReduce}: {Review} and open challenges},
	volume = {109},
	issn = {0138-9130, 1588-2861},
	shorttitle = {{MapReduce}},
	url = {http://link.springer.com/10.1007/s11192-016-1945-y},
	doi = {10.1007/s11192-016-1945-y},
	language = {en},
	number = {1},
	urldate = {2024-12-29},
	journal = {Scientometrics},
	author = {Hashem, Ibrahim Abaker Targio and Anuar, Nor Badrul and Gani, Abdullah and Yaqoob, Ibrar and Xia, Feng and Khan, Samee Ullah},
	month = oct,
	year = {2016},
	pages = {389--422},
	file = {PDF:/Users/vishal/Zotero/storage/JXS8EZIG/Hashem et al. - 2016 - MapReduce Review and open challenges.pdf:application/pdf},
}

@book{rahman_python_2021,
	title = {Python {Data} {Visualization} {Essentials} {Guide}: {Become} a {Data} {Visualization} expert by building strong proficiency in {Pandas}, {Matplotlib}, {Seaborn}, {Plotly}, {Numpy}, and {Bokeh} ({English} {Edition})},
	isbn = {978-93-91030-07-0},
	shorttitle = {Python {Data} {Visualization} {Essentials} {Guide}},
	abstract = {Build your data science skills. Start data visualization Using Python. Right away. Become a good data analyst by creating quality data visualizations using Python. 	 KEY FEATURES  ● Exciting coverage on loads of Python libraries, including Matplotlib, Seaborn, Pandas, and Plotly.● Tons of examples, illustrations, and use-cases to demonstrate visual storytelling of varied datasets.● Covers a strong fundamental understanding of exploratory data analysis (EDA), statistical modeling, and data mining. DESCRIPTION Data visualization plays a major role in solving data science challenges with various capabilities it offers. This book aims to equip you with a sound knowledge of Python in conjunction with the concepts you need to master to succeed as a data visualization expert.The book starts with a brief introduction to the world of data visualization and talks about why it is important, the history of visualization, and the capabilities it offers. You will learn how to do simple Python-based visualization with examples with progressive complexity of key features. The book starts with Matplotlib and explores the power of data visualization with over 50 examples. It then explores the power of data visualization using one of the popular exploratory data analysis-oriented libraries, Pandas.The book talks about statistically inclined data visualization libraries such as Seaborn. The book also teaches how we can leverage bokeh and Plotly for interactive data visualization. Each chapter is enriched and loaded with 30+ examples that will guide you in learning everything about data visualization and storytelling of mixed datasets.WHAT YOU WILL LEARN● Learn to work with popular Python libraries and frameworks, including Seaborn, Bokeh, and Plotly.● Practice your data visualization understanding across numerous datasets and real examples.● Learn to visualize geospatial and time-series datasets.● Perform correlation and EDA analysis using Pandas and Matplotlib.● Get to know storytelling of complex and unstructured data using Bokeh and Pandas.● Learn best practices in writing clean and short python scripts for a quicker visual summary of datasets. WHO THIS BOOK IS FOR  This book is for all data analytics professionals, data scientists, and data mining hobbyists who want to be strong data visualizers by learning all the popular Python data visualization libraries. Prior working knowledge of Python is assumed.TABLE OF CONTENTS1. Introduction to Data Visualization2. Why Data Visualization3. Various Data Visualization Elements and Tools4. Using Matplotlib with Python5. Using NumPy and Pandas for Plotting6. Using Seaborn for Visualization7. Using Bokeh with Python8. Using Plotly, Folium, and Other Tools for Data Visualization9. Hands-on Examples and Exercises, Case Studies, and Further Resources},
	language = {en},
	urldate = {2024-12-29},
	publisher = {BPB Publications},
	author = {Rahman, Kallur},
	month = jul,
	year = {2021},
	note = {Google-Books-ID: kOU6EAAAQBAJ},
	keywords = {Computers / Data Science / Data Analytics, Computers / Data Science / Data Visualization, Computers / Data Science / General, Computers / Languages / Python},
}

@misc{david_pareto_2022,
	title = {The {Pareto} principle — {Game}-changer to {ML} {Engineers} in 2022},
	url = {https://medium.com/analytics-vidhya/the-pareto-principle-game-changer-to-ml-engineers-in-2022-72c53673cb91},
	abstract = {A minority of effort will get the majority of the outcome},
	language = {en},
	urldate = {2025-01-01},
	journal = {Analytics Vidhya},
	author = {David, Elvis},
	month = feb,
	year = {2022},
	file = {Snapshot:/Users/vishal/Zotero/storage/CHMK79E2/the-pareto-principle-game-changer-to-ml-engineers-in-2022-72c53673cb91.html:text/html},
}

@misc{glauber_collaborative_2019,
	title = {Collaborative {Filtering} vs. {Content}-{Based} {Filtering}: differences and similarities},
	shorttitle = {Collaborative {Filtering} vs. {Content}-{Based} {Filtering}},
	url = {http://arxiv.org/abs/1912.08932},
	doi = {10.48550/arXiv.1912.08932},
	abstract = {Recommendation Systems (SR) suggest items exploring user preferences, helping them with the information overload problem. Two approaches to SR have received more prominence, Collaborative Filtering, and Content-Based Filtering. Moreover, even though studies are indicating their advantages and disadvantages, few results empirically prove their characteristics, similarities, and differences. In this work, an experimental methodology is proposed to perform comparisons between recommendation algorithms for different approaches going beyond the "precision of the predictions". For the experiments, three algorithms of recommendation were tested: a baseline for Collaborative Filtration and two algorithms for Content-based Filtering that were developed for this evaluation. The experiments demonstrate the behavior of these systems in different data sets, its main characteristics and especially the complementary aspect of the two main approaches.},
	urldate = {2025-01-02},
	publisher = {arXiv},
	author = {Glauber, Rafael and Loula, Angelo},
	month = dec,
	year = {2019},
	note = {arXiv:1912.08932 [cs]
version: 1},
	keywords = {Computer Science - Information Retrieval},
	file = {Full Text PDF:/Users/vishal/Zotero/storage/DVPX2B8T/Glauber and Loula - 2019 - Collaborative Filtering vs. Content-Based Filtering differences and similarities.pdf:application/pdf;Snapshot:/Users/vishal/Zotero/storage/BY6HKHER/1912.html:text/html},
}
